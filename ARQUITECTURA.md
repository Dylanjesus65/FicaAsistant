# üèóÔ∏è Arquitectura del Sistema FicaAsistant

Este documento describe la arquitectura t√©cnica del chatbot **FicaAsistant**, detallando c√≥mo interact√∫an Django, los WebSockets y el modelo de IA Llama-3.2-v3 para ofrecer respuestas en tiempo real.

---

## üß© Diagrama de Arquitectura

El siguiente diagrama ilustra el flujo de datos desde que el usuario env√≠a un mensaje hasta que recibe la respuesta generada por la IA.

```mermaid
graph TD
    User(["üë§ Usuario"])
    Browser["üåê Navegador (Frontend)"]
    
    subgraph "Backend Server (Daphne/Django)"
        ASGI["üîå ASGI Interface (Daphne)"]
        Router["üîÄ URL Router (Django Channels)"]
        Consumer["‚ö° ChatConsumer (Async)"]
        
        subgraph "IA Engine (GPU)"
            Tokenizer["üî§ Tokenizer"]
            Model["üß† Llama-3.2-3B (4-bit)"]
            Thread["üßµ Generation Thread"]
        end
    end
    
    User -->|"Escribe Mensaje"| Browser
    Browser -->|"WebSocket (JSON)"| ASGI
    ASGI -->|"Route /ws/chat/"| Router
    Router -->|"Instancia"| Consumer
    
    Consumer -->|"Restores History"| Consumer
    Consumer -->|"Inputs"| Tokenizer
    Tokenizer -->|"Tokens"| Model
    
    Model -.->|"Stream Tokens"| Thread
    Thread -.->|"Yield Tokens"| Consumer
    Consumer -->|"Send JSON"| ASGI
    ASGI -->|"WebSocket Stream"| Browser
    Browser -->|"Renderiza"| User
```

---

## üõ†Ô∏è Componentes Principales

### 1. Frontend (La Cara)
*   **Tecnolog√≠a**: HTML5, CSS3, JavaScript (Vanilla).
*   **Responsabilidad**:
    *   Gestionar la interfaz de chat (burbujas de mensaje, modo oscuro).
    *   Mantener la conexi√≥n persistente v√≠a **WebSockets** (`ws://...`).
    *   Renderizar los tokens en tiempo real a medida que llegan ("efecto m√°quina de escribir").
    *   Gestionar el historial de chat para reconexiones.

### 2. Servidor Web & WebSockets (El Sistema Nervioso)
*   **Tecnolog√≠a**: **Django 5.0** + **Django Channels** + **Daphne**.
*   **Por qu√© WebSockets?**: A diferencia de HTTP tradicional (donde se pide una p√°gina completa), los WebSockets permiten una conexi√≥n bidireccional permanente. Esto es crucial para el **streaming** de texto, permitiendo que la IA env√≠e palabra por palabra sin recargar la p√°gina.
*   **Daphne**: Es el servidor ASGI que maneja tanto peticiones HTTP (vistas normales) como conexiones WebSocket as√≠ncronas.

### 3. Motor de Inteligencia Artificial (El Cerebro)
*   **Modelo Base**: `unsloth/Llama-3.2-3B-Instruct`.
*   **Fine-Tuning**: Adaptadores LoRA entrenados espec√≠ficamente con normativa universitaria.
*   **Eficiencia**:
    *   **Cuantizaci√≥n 4-bit (`bitsandbytes`)**: Reduce el uso de memoria VRAM para que el modelo corra en una GPU de consumo (8GB).
    *   **PEFT (Parameter-Efficient Fine-Tuning)**: En lugar de cargar todo el modelo re-entrenado, cargamos el modelo base + capas ligeras (adaptadores), lo que es m√°s r√°pido y eficiente.

---

## üîÑ Flujo Completo de una Interacci√≥n

1.  **Conexi√≥n y Restauraci√≥n**: 
    Al abrir la p√°gina, el navegador inicia un handshake WebSocket con `/ws/chat/`. 
    *   Si es la primera vez, se inicializa el historial con la *Instrucci√≥n del Sistema*.
    *   Si el usuario recarga la p√°gina, el navegador env√≠a autom√°ticamente el historial previo (`restore_history: true`) para mantener el contexto de la conversaci√≥n.

2.  **Recepci√≥n del Mensaje**:
    El usuario env√≠a `{"message": "¬øCu√°ndo son las matr√≠culas?"}`. El consumidor recibe el JSON y lo agrega al historial de la conversaci√≥n.

3.  **Procesamiento (Tokenizaci√≥n)**:
    El mensaje text es convertido a n√∫meros (tokens) entendibles por el modelo usando el `AutoTokenizer`.

4.  **Generaci√≥n As√≠ncrona (Streaming)**:
    *   Aqu√≠ ocurre la magia. Django no espera a que la IA termine de pensar toda la frase.
    *   Se lanza un **Hilo (Thread)** separado para la generaci√≥n.
    *   Se usa `TextIteratorStreamer` para capturar cada nuevo token generado en tiempo real.

5.  **Env√≠o de Respuesta**:
    *   El `ChatConsumer` lee los tokens del streamer uno por uno.
    *   Env√≠a cada fragmento v√≠a WebSocket: `{"type": "stream", "content": "Las"}` ... `{"type": "stream", "content": " matr√≠culas"}` ...
    *   El navegador concatena estos fragmentos instant√°neamente en la pantalla.

6.  **Finalizaci√≥n**:
    Cuando el modelo detecta que termin√≥ la respuesta, env√≠a un token especial de fin (`EOS`). El consumidor cierra el stream y espera la siguiente pregunta.

---

## üìÇ Estructura de Archivos Clave

| Archivo | Funci√≥n |
|---------|---------|
| `chatbot/asgi.py` | Punto de entrada del servidor. Decide si una petici√≥n es HTTP o WebSocket. |
| `chatbot_app/routing.py` | "Mapa" que dice qu√© c√≥digo maneja la URL `/ws/chat/`. |
| `chatbot_app/consumers.py` | **El n√∫cleo**. Carga el modelo IA, maneja la l√≥gica del chat y el streaming. |
| `chatbot_app/templates/chat.html` | El cliente web. Contiene el JavaScript que conecta al WebSocket. |

---

## üöÄ Tecnolog√≠as Utilizadas

*   **Python**: Lenguaje principal.
*   **Django**: Framework web.
*   **Channels**: Extensi√≥n de Django para WebSockets.
*   **PyTorch**: Framework de Deep Learning.
*   **Transformers (Hugging Face)**: Librer√≠a para cargar y usar Llama-3.
*   **Unsloth**: Librer√≠a de optimizaci√≥n que permiti√≥ entrenar el modelo 2x m√°s r√°pido.
