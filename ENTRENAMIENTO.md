# üéì Flujo de Entrenamiento del Modelo FicaAsistant

Este documento detalla el proceso t√©cnico completo para crear el modelo de IA: desde la ingesta de PDFs crudos hasta el Fine-Tuning final utilizando t√©cnicas avanzadas de optimizaci√≥n.

---

## üîÑ Pipeline de Entrenamiento

```mermaid
graph TD
    subgraph "1. Ingesta de Datos"
        PDFs[üìÑ PDFs Normativa] -->|pdfplumber/OCR| RawText[üìù Texto Crudo]
        RawText -->|Limpieza| CleanText[üßπ Texto Limpio]
    end

    subgraph "2. Generaci√≥n Sint√©tica (Dataset Builder)"
        CleanText -->|Segmentaci√≥n| Articles[üìå Art√≠culos Identificados]
        Articles -->|Estrategia 1| Q1[‚ùì Pregunta Directa]
        Articles -->|Estrategia 2| Q2[‚ùì Pregunta por Tema]
        Articles -->|Estrategia 3| Q3[‚ùì Pregunta Coloquial]
        Anti[üõ°Ô∏è Ejemplos Royecto Anti-Alucinaci√≥n] --> Dataset
        Q1 & Q2 & Q3 --> Dataset[üìö Dataset JSONL]
    end

    subgraph "3. Fine-Tuning (Train V3)"
        Dataset -->|Split 85/15| TrainSet & TestSet
        BaseModel[üß† Llama-3.2-3B] -->|QLoRA 4-bit| Trainer
        TrainSet --> Trainer[üèãÔ∏è SFT Trainer]
        Trainer -->|2000 Pasos| Adapter[üíæ Adaptadores LoRA]
    end
```

---

## üõ†Ô∏è Fase 1: Ingenier√≠a de Datos (`Dataset Builder V3`)

El mayor desaf√≠o fue convertir documentos PDF est√°ticos en conocimientos conversacionales. No usamos un LLM externo para generar preguntas, sino un **motor de reglas determinista** dise√±ado en Python.

### 1.1 Extracci√≥n y Limpieza
*   **Lectura H√≠brida**: Usamos `pdfplumber` para PDFs digitales y `pytesseract` (OCR) como respaldo si el documento era escaneado.
*   **Limpieza de Ruido**: Se eliminaron encabezados repetitivos ("UNIVERSIDAD T√âCNICA DEL NORTE", "RECTORADO") y pies de p√°gina para no "ensuciar" el contexto.
*   **Segmentaci√≥n**: Usamos Expresiones Regulares (`Regex`) para detectar autom√°ticamente el inicio de cada art√≠culo (`ART√çCULO \d+`, `DISPOSICI√ìN...`).

### 1.2 Sintetizaci√≥n de Preguntas (Strategies)
Por cada art√≠culo extra√≠do, el script genera autom√°ticamente 3 variantes de entrenamiento para ense√±ar al modelo a generalizar:

| Estrategia | Ejemplo Generado | Objetivo |
|------------|------------------|----------|
| **1. Directa** | "¬øQu√© dice el Art√≠culo 45?" | Memorizaci√≥n exacta de la referencia. |
| **2. Tem√°tica** | "¬øQu√© establece la normativa sobre las matr√≠culas extraordinarias?" | Asociaci√≥n de conceptos clave. |
| **3. Coloquial** | "Expl√≠came c√≥mo funcionan las matr√≠culas" | Comprensi√≥n de lenguaje natural. |

### 1.3 Mecanismo Anti-Alucinaci√≥n
Para evitar que el bot responda cosas que no sabe (como preguntas de f√∫tbol, medicina, o ubicaci√≥n de edificios que no est√°n en los PDFs), inyectamos **ejemplos negativos** manuales.
*   **Input**: "¬øQui√©n gan√≥ el mundial?"
*   **Target**: "No tengo esa informaci√≥n en la normativa universitaria."

Esto "ense√±a" al modelo a rechazar amablemente preguntas fuera de su dominio.

---

## ‚öôÔ∏è Fase 2: Fine-Tuning con QLoRA

Entrenar un modelo de 3 billones de par√°metros desde cero es costoso. Usamos **QLoRA (Quantized Low-Rank Adaptation)** para hacerlo eficiente en una sola GPU.

### Configuraci√≥n del Entrenamiento (`train_peft_v3.py`)

*   **Modelo Base**: `unsloth/Llama-3.2-3B-Instruct`.
*   **Librer√≠a**: `Unsloth` (optimiza el entrenamiento para ser 2x m√°s r√°pido y usar 70% menos memoria).
*   **Hiperpar√°metros Clave**:
    *   **Max Steps**: `2000` (Garantiza convergencia profunda).
    *   **Learning Rate**: `1e-4` (Estabilidad).
    *   **Batch Size**: `1` (Con acumulaci√≥n de gradiente = 2).
    *   **LoRA Rank (r)**: `32` (Capacidad media-alta para aprender nuevos conceptos).
    *   **LoRA Alpha**: `64` (Factor de escala).

### ¬øPor qu√© Llama-3.2?
Es un modelo "Small Language Model" (SLM) optimizado para dispositivos de borde. Sus 3B de par√°metros son suficientes para dominar un dominio cerrado (normativa) sin requerir servidores masivos.

---

## üìä Fase 3: Evaluaci√≥n y Divisi√≥n

El dataset generado se dividi√≥ autom√°ticamente en:
*   **Train (85%)**: Para ense√±ar al modelo.
*   **Test (15%)**: Para evaluar rendimiento (Loss y Perplexity) durante el entrenamiento y evitar Overfitting.

### M√©tricas Observadas
Durante los 2000 pasos, monitoreamos la **P√©rdida de Evaluaci√≥n (Eval Loss)**. Una curva descendente constante indic√≥ que el modelo estaba aprendiendo correctamente la sintaxis y el contenido de la normativa, en lugar de solo memorizar.

---

## üìÇ Archivos Relacionados

| Archivo | Descripci√≥n |
|---------|-------------|
| `dataset_builder_v3.py` | Script principal de extracci√≥n y generaci√≥n de datos. |
| `train_peft_v3.py` | Script de entrenamiento con configuraci√≥n de hiperpar√°metros. |
| `requirements_unsloth.txt` | Dependencias espec√≠ficas para el entorno de entrenamiento. |
